{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104383,"databundleVersionId":12957508,"sourceType":"competition"},{"sourceId":528127,"sourceType":"modelInstanceVersion","modelInstanceId":413145,"modelId":430885},{"sourceId":529891,"sourceType":"modelInstanceVersion","modelInstanceId":414496,"modelId":432264},{"sourceId":540760,"sourceType":"modelInstanceVersion","modelInstanceId":417923,"modelId":435592},{"sourceId":541597,"sourceType":"modelInstanceVersion","modelInstanceId":418051,"modelId":435712},{"sourceId":541860,"sourceType":"modelInstanceVersion","modelInstanceId":418104,"modelId":435769},{"sourceId":542711,"sourceType":"modelInstanceVersion","modelInstanceId":418182,"modelId":435846},{"sourceId":548733,"sourceType":"modelInstanceVersion","modelInstanceId":419371,"modelId":437030},{"sourceId":548996,"sourceType":"modelInstanceVersion","modelInstanceId":419512,"modelId":437159},{"sourceId":549135,"sourceType":"modelInstanceVersion","modelInstanceId":419575,"modelId":437216},{"sourceId":549169,"sourceType":"modelInstanceVersion","modelInstanceId":419587,"modelId":437226},{"sourceId":551615,"sourceType":"modelInstanceVersion","modelInstanceId":420951,"modelId":438575},{"sourceId":557916,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":423985,"modelId":441496}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MAP - Charting Student Math Misunderstandings","metadata":{"_uuid":"2a9297b6-f347-4772-847a-4f5158588d75","_cell_guid":"5fd3d91a-567f-4ef7-9b9d-cb524befdf55","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"### Install Requirements","metadata":{}},{"cell_type":"markdown","source":"## Imports and Data Loading","metadata":{"_uuid":"d739f6b5-50d2-4dc5-8624-d7f4ee855ba6","_cell_guid":"aeff8aaf-3cce-49e4-b9c2-0b179be393ea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Import basic libraries\nimport pandas as pd  \nimport numpy as np  \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport io\nimport os\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder \nfrom sklearn.model_selection import train_test_split, cross_val_score \nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import f1_score, precision_score, recall_score, auc, roc_curve, roc_auc_score, precision_recall_fscore_support\nimport joblib\n\n\n# Import tensorflow, and keras modules\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D\nfrom tensorflow.keras.layers import Dropout, Dense, LSTM, Input, Masking, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Import transformers and pytorch modules\nfrom transformers import RobertaTokenizerFast, RobertaForSequenceClassification, TrainingArguments, Trainer,  DataCollatorWithPadding\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorForLanguageModeling\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM, Trainer, TrainingArguments\nfrom transformers import DistilBertTokenizer, DistilBertForMaskedLM, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom transformers import RobertaForSequenceClassification,DataCollatorForLanguageModeling\nfrom transformers import DistilBertForSequenceClassification, DataCollatorForLanguageModeling\nfrom transformers import get_linear_schedule_with_warmup\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom datasets import load_dataset, Dataset as HFDataset, DatasetDict\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM, Trainer, TrainingArguments\nfrom transformers import DistilBertTokenizer, DistilBertForMaskedLM, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom transformers import RobertaForSequenceClassification,DataCollatorForLanguageModeling\nfrom transformers import DistilBertForSequenceClassification, DataCollatorForLanguageModeling\nfrom datasets import Dataset\nimport torch\nfrom tqdm import tqdm\nimport os\n\n# Disable warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8efff134-af25-4b87-8434-874e129a866c","_cell_guid":"9a913737-80d3-40e9-b3f3-3e78c01e6ac0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Load & train and test data\ndata = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')","metadata":{"_uuid":"efc9e40b-80a6-4186-99b0-bdeb54211143","_cell_guid":"39ca4580-c661-4e86-a75b-19616d9997e0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-03T14:57:11.490717Z","iopub.execute_input":"2025-09-03T14:57:11.491170Z","iopub.status.idle":"2025-09-03T14:57:11.758270Z","shell.execute_reply.started":"2025-09-03T14:57:11.490992Z","shell.execute_reply":"2025-09-03T14:57:11.757348Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"_uuid":"0f2aa5c3-d21f-49fb-a951-de4713481c55","_cell_guid":"125e357d-263e-4b2f-bcee-018134132dad","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T14:57:12.889192Z","iopub.execute_input":"2025-09-03T14:57:12.890239Z","iopub.status.idle":"2025-09-03T14:57:12.947917Z","shell.execute_reply.started":"2025-09-03T14:57:12.890197Z","shell.execute_reply":"2025-09-03T14:57:12.946659Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Impute missing values for the `Misconception` column with NA\ndata['Misconception'] = data['Misconception'].fillna('NA')","metadata":{"_uuid":"d991ee2e-3d4f-4dcd-b2d0-e2c66bad08d1","_cell_guid":"21871582-6c90-4b59-a702-4980f91f3d75","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T14:57:14.552855Z","iopub.execute_input":"2025-09-03T14:57:14.553274Z","iopub.status.idle":"2025-09-03T14:57:14.563230Z","shell.execute_reply.started":"2025-09-03T14:57:14.553252Z","shell.execute_reply":"2025-09-03T14:57:14.561973Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['combined_label'] = data['Category'].astype(str) + ':' + data['Misconception'].astype(str)\ncat = pd.Categorical(data['combined_label'])\ny = cat.codes\nnum_classes = len(cat.categories)\nlabel_to_original = dict(enumerate(cat.categories))\n\nprint(f\" Number of classes: {num_classes}\")\nprint(f\" Label range: 0 to {num_classes - 1}\")\n\n# Save mapping\njoblib.dump(label_to_original, \"label_to_original.pkl\")","metadata":{"_uuid":"190544b6-b69e-444f-bfa5-6e70dd2692d3","_cell_guid":"017fb7d3-8ec3-40ea-87bb-c5e054d83ebd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-03T14:57:15.978712Z","iopub.execute_input":"2025-09-03T14:57:15.979027Z","iopub.status.idle":"2025-09-03T14:57:16.012250Z","shell.execute_reply.started":"2025-09-03T14:57:15.979003Z","shell.execute_reply":"2025-09-03T14:57:16.011330Z"}},"outputs":[{"name":"stdout","text":" Number of classes: 65\n Label range: 0 to 64\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['label_to_original.pkl']"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# drop labels that have less than 1 entities for the `combined_label` column\nclasses_to_keep = data['combined_label'].value_counts()[data['combined_label'].value_counts() >= 2].index\ntrain = data[data['combined_label'].isin(classes_to_keep)] \ntrain.head(2)","metadata":{"_uuid":"afd14737-7389-438d-b8ec-5e9f931761d6","_cell_guid":"bee0891d-e7ba-4907-b7ab-f484fc7ecd3d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T14:57:18.892275Z","iopub.execute_input":"2025-09-03T14:57:18.892718Z","iopub.status.idle":"2025-09-03T14:57:18.930562Z","shell.execute_reply.started":"2025-09-03T14:57:18.892690Z","shell.execute_reply":"2025-09-03T14:57:18.929192Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   row_id  QuestionId                                       QuestionText  \\\n0       0       31772  What fraction of the shape is not shaded? Give...   \n1       1       31772  What fraction of the shape is not shaded? Give...   \n\n           MC_Answer                                 StudentExplanation  \\\n0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n\n       Category Misconception   combined_label  \n0  True_Correct            NA  True_Correct:NA  \n1  True_Correct            NA  True_Correct:NA  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>QuestionId</th>\n      <th>QuestionText</th>\n      <th>MC_Answer</th>\n      <th>StudentExplanation</th>\n      <th>Category</th>\n      <th>Misconception</th>\n      <th>combined_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>\\( \\frac{1}{3} \\)</td>\n      <td>0ne third is equal to tree nineth</td>\n      <td>True_Correct</td>\n      <td>NA</td>\n      <td>True_Correct:NA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>\\( \\frac{1}{3} \\)</td>\n      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n      <td>True_Correct</td>\n      <td>NA</td>\n      <td>True_Correct:NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:57:20.618519Z","iopub.execute_input":"2025-09-03T14:57:20.619308Z","iopub.status.idle":"2025-09-03T14:57:20.667800Z","shell.execute_reply.started":"2025-09-03T14:57:20.619265Z","shell.execute_reply":"2025-09-03T14:57:20.666208Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 36691 entries, 0 to 36695\nData columns (total 8 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   row_id              36691 non-null  int64 \n 1   QuestionId          36691 non-null  int64 \n 2   QuestionText        36691 non-null  object\n 3   MC_Answer           36691 non-null  object\n 4   StudentExplanation  36691 non-null  object\n 5   Category            36691 non-null  object\n 6   Misconception       36691 non-null  object\n 7   combined_label      36691 non-null  object\ndtypes: int64(2), object(6)\nmemory usage: 2.5+ MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Encode the labels to numeric values\nle = LabelEncoder()\ny = le.fit_transform(train['combined_label'])\nnum_classes = len(le.classes_)\n\n# Save label mapping for later use during inference\nlabel_to_original = dict(enumerate(le.classes_))\njoblib.dump(label_to_original, \"label_to_original.pkl\")\nprint(f\"Number of misconception classes: {num_classes}\")\nprint(f\"Label range: 0 to {num_classes-1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:57:23.044960Z","iopub.execute_input":"2025-09-03T14:57:23.045270Z","iopub.status.idle":"2025-09-03T14:57:23.065628Z","shell.execute_reply.started":"2025-09-03T14:57:23.045242Z","shell.execute_reply":"2025-09-03T14:57:23.064298Z"}},"outputs":[{"name":"stdout","text":"Number of misconception classes: 60\nLabel range: 0 to 59\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Determine if CUDA (GPU) is available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:57:24.576401Z","iopub.execute_input":"2025-09-03T14:57:24.576759Z","iopub.status.idle":"2025-09-03T14:57:24.581941Z","shell.execute_reply.started":"2025-09-03T14:57:24.576734Z","shell.execute_reply":"2025-09-03T14:57:24.580732Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data = train.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:57:44.211686Z","iopub.execute_input":"2025-09-03T14:57:44.212010Z","iopub.status.idle":"2025-09-03T14:57:44.225670Z","shell.execute_reply.started":"2025-09-03T14:57:44.211985Z","shell.execute_reply":"2025-09-03T14:57:44.224436Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# # Pretrain the scibert transformer\n# # Create pretraining corpus \n# def create_pretrain_text(row):\n#     return (\n#         f\"[question text]: {row['QuestionText']}\"\n#         f\"[student answer] {row['MC_Answer']}\"\n#         f\"[student explanation] {row['StudentExplanation']}\" \n#         f\"[label] {row['combined_label']}\" \n# )\n\n# pretrain_corpus = train_data.apply(create_pretrain_text, axis=1).tolist()\n\n# # Create a Hugging Face Dataset\n# dataset = Dataset.from_dict({'text': pretrain_corpus}) \n\n# # Load tokenizer and model\n# scibert_base = '/kaggle/input/scibert-base-offline/transformers/default/1/scibert-base-offline'\n# # scibert_base = \"allenai/scibert_scivocab_uncased\"\n# tokenizer = AutoTokenizer.from_pretrained(scibert_base)\n# model = AutoModelForMaskedLM.from_pretrained(scibert_base).to(device)\n\n# # Tokenize the dataset with dynamic padding\n# def tokenize_function(examples):\n#     return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n\n# tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n# tokenized_dataset.set_format('torch')  \n\n# # Data collator for MLM \n# data_collator = DataCollatorForLanguageModeling(\n#     tokenizer=tokenizer,\n#     mlm=True,\n#     mlm_probability=0.30 \n# )\n\n# # Training arguments with optimizations\n# training_args = TrainingArguments(\n#     output_dir='./scibert-pretrain',\n#     overwrite_output_dir=True,\n#     num_train_epochs=3,\n#     per_device_train_batch_size=16,\n#     gradient_accumulation_steps=2,\n#     save_steps=5_000,\n#     save_total_limit=2,\n#     logging_dir='./logs',\n#     logging_steps=500,  \n#     report_to=[],\n#     learning_rate=2e-5,\n#     warmup_steps=500,\n#     fp16=True,\n# )\n\n# # Trainer with optimized settings\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=tokenized_dataset,\n#     data_collator=data_collator,\n# )\n\n# # Start pretraining\n# trainer.train()\n\n# # Save the pretrained model\n# model.save_pretrained('./scibert-pretrained')\n# tokenizer.save_pretrained('./scibert-pretrained')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T09:04:13.230845Z","iopub.execute_input":"2025-09-03T09:04:13.231207Z","execution_failed":"2025-09-03T09:07:26.182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create finetuning corpus \ndef create_finetune_text(row):\n    return (\n        f\"[question text]: {row['QuestionText']}\"\n        f\"[student answer] {row['MC_Answer']}\"\n        f\"[student explanation] {row['StudentExplanation']}\" \n)\n# train_data['train_text'] = train_data.apply(create_finetune_text, axis=1)","metadata":{"_uuid":"8fed60f0-6090-4b7d-8442-3dbd0504a024","_cell_guid":"b0889a34-277b-4435-a96e-b50e756c1e4e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-03T14:57:47.227444Z","iopub.execute_input":"2025-09-03T14:57:47.227775Z","iopub.status.idle":"2025-09-03T14:57:47.233229Z","shell.execute_reply.started":"2025-09-03T14:57:47.227751Z","shell.execute_reply":"2025-09-03T14:57:47.232265Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# train_data.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T06:43:55.875784Z","iopub.execute_input":"2025-09-03T06:43:55.876079Z","iopub.status.idle":"2025-09-03T06:43:55.889214Z","shell.execute_reply.started":"2025-09-03T06:43:55.876058Z","shell.execute_reply":"2025-09-03T06:43:55.888105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-test split\n# train_texts, val_texts, train_labels, val_labels = train_test_split(train_data['text'].values, y, test_size=0.3, random_state=42, stratify=y)","metadata":{"_uuid":"852960de-3ca6-4987-8ea2-c47721236d2a","_cell_guid":"17f736f6-a79f-4344-9098-ac1be91ff593","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.348637Z","iopub.execute_input":"2025-08-29T23:55:38.348916Z","iopub.status.idle":"2025-08-29T23:55:38.366227Z","shell.execute_reply.started":"2025-08-29T23:55:38.348900Z","shell.execute_reply":"2025-08-29T23:55:38.365523Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Finetune the SciBERT Transformer Model","metadata":{}},{"cell_type":"code","source":"# # Set device\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# print(f\"Using device: {device}\")\n# if device.type == 'cuda':\n#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"87bdcf9a-0a78-4e17-9f5c-93bd4895d3fa","_cell_guid":"e67237d9-9e9d-4fdb-9485-be511be26a11","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.367011Z","iopub.execute_input":"2025-08-29T23:55:38.367242Z","iopub.status.idle":"2025-08-29T23:55:38.421608Z","shell.execute_reply.started":"2025-08-29T23:55:38.367223Z","shell.execute_reply":"2025-08-29T23:55:38.421087Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load RoBERTa tokenizer\n# tokenizer = AutoTokenizer.from_pretrained(\"./scibert-pretrained\")\n# MAX_LEN = 256","metadata":{"_uuid":"4c295ba9-cb8c-4c43-b091-ef93c2b4a99f","_cell_guid":"b4ffc16f-2741-4337-b8d8-bf674d25ded4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.422283Z","iopub.execute_input":"2025-08-29T23:55:38.422519Z","iopub.status.idle":"2025-08-29T23:55:38.432050Z","shell.execute_reply.started":"2025-08-29T23:55:38.422502Z","shell.execute_reply":"2025-08-29T23:55:38.431395Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Define custom dataset class\n# class MathMisconceptionDataset(Dataset):\n#     def __init__(self, texts, labels, tokenizer, max_len):\n#         self.texts = texts\n#         self.labels = labels\n#         self.tokenizer = tokenizer\n#         self.max_len = max_len\n        \n#     def __len__(self):\n#         return len(self.texts)\n    \n#     def __getitem__(self, idx):\n#         text = str(self.texts[idx])\n#         label = self.labels[idx]\n        \n#         # Tokenize the text \n#         encoding = self.tokenizer.encode_plus(\n#             text,\n#             add_special_tokens=True,      \n#             max_length=self.max_len,      \n#             return_token_type_ids=False,  \n#             padding='max_length',         \n#             truncation=True,              \n#             return_attention_mask=True,   \n#             return_tensors='pt',         \n#         )\n        \n#         return {\n#             'input_ids': encoding['input_ids'].flatten(),\n#             'attention_mask': encoding['attention_mask'].flatten(),\n#             'label': torch.tensor(label, dtype=torch.long)\n#         }\n\n# # Create dataset instances for training and validation\n# train_dataset = MathMisconceptionDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n# val_dataset = MathMisconceptionDataset(val_texts, val_labels, tokenizer, MAX_LEN)","metadata":{"_uuid":"07454838-24cd-46ab-8bb8-bee111c135de","_cell_guid":"e7aec855-d936-40eb-9746-6e2c492c19b1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.432731Z","iopub.execute_input":"2025-08-29T23:55:38.432942Z","iopub.status.idle":"2025-08-29T23:55:38.443190Z","shell.execute_reply.started":"2025-08-29T23:55:38.432908Z","shell.execute_reply":"2025-08-29T23:55:38.442575Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Data Loading\n\n# BATCH_SIZE = 16 \n\n# # Create data loaders (train set)\n# train_dataloader = DataLoader(\n#     train_dataset,\n#     batch_size=BATCH_SIZE,\n#     shuffle=True,      \n#     num_workers=2,     \n#     pin_memory=True)\n\n# # Create data loaders (validation set)\n# val_dataloader = DataLoader(\n#     val_dataset,\n#     batch_size=BATCH_SIZE,\n#     shuffle=False,     \n#     num_workers=2,\n#     pin_memory=True)\n","metadata":{"_uuid":"e447cc0f-3f80-4e8c-bc95-6beaf0876cbe","_cell_guid":"0d81b9f2-db6b-4a37-9904-bf45b97466ee","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.444131Z","iopub.execute_input":"2025-08-29T23:55:38.444368Z","iopub.status.idle":"2025-08-29T23:55:38.474887Z","shell.execute_reply.started":"2025-08-29T23:55:38.444348Z","shell.execute_reply":"2025-08-29T23:55:38.474373Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Configure model\n# model = AutoModelForSequenceClassification.from_pretrained(\n#     \"./scibert-pretrained\",\n#     num_labels=num_classes,  \n#     output_attentions=False, \n#     output_hidden_states=False)\n\n# model = model.to(device)\n\n# # Configure optimizer\n# optimizer = optim.AdamW(\n#     model.parameters(),\n#     lr=2e-5,          \n#     eps=1e-8,)\n\n# # Define training parameters\n# EPOCHS = 4            \n# WARMUP_STEPS = 0      \n\n# # Calculate total training steps \n# total_steps = len(train_dataloader) * EPOCHS\n\n# # Create learning rate scheduler\n# scheduler = get_linear_schedule_with_warmup(\n#     optimizer,\n#     num_warmup_steps=WARMUP_STEPS,\n#     num_training_steps=total_steps)","metadata":{"_uuid":"f87a317a-0d7f-48cb-bd4c-0fcb249caed4","_cell_guid":"09f6c3e7-f4fc-4f0e-86fc-b4869d535007","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T09:09:11.659819Z","iopub.execute_input":"2025-09-03T09:09:11.660539Z","iopub.status.idle":"2025-09-03T09:09:11.747217Z","shell.execute_reply.started":"2025-09-03T09:09:11.660512Z","shell.execute_reply":"2025-09-03T09:09:11.745813Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Define map3 metric\n# def map_at_3(predictions, true_labels):\n    \n#     # Get top-3 predicted class indices for each sample in descending order\n#     top_3_pred = np.argsort(predictions, axis=1)[:, -3:][:, ::-1]\n\n#     # List average precisions \n#     aps = []  \n#     for i in range(len(true_labels)):\n#         true_label = true_labels[i]\n#         preds = top_3_pred[i]\n#         hits = (preds == true_label)\n#         if not np.any(hits):\n#             aps.append(0.0)  \n#         else:\n#             rank = np.where(hits)[0][0] + 1\n#             precision_at_k = 1.0 / rank\n#             aps.append(precision_at_k)\n            \n#     return np.mean(aps)","metadata":{"_uuid":"e738be4d-2343-402d-879e-73878c6fd80d","_cell_guid":"f2c8e618-6f04-4c87-abd6-630bf2e14471","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.480721Z","iopub.execute_input":"2025-08-29T23:55:38.480952Z","iopub.status.idle":"2025-08-29T23:55:38.493556Z","shell.execute_reply.started":"2025-08-29T23:55:38.480937Z","shell.execute_reply":"2025-08-29T23:55:38.492759Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Define training function\n# def train_epoch(model, dataloader, optimizer, scheduler, device):\n#     model.train()\n#     total_loss = 0\n#     all_preds = []\n#     all_labels = []\n\n#     # Process batches with progress bar\n#     for batch in tqdm(dataloader, desc=\"Training\"):\n#         input_ids = batch['input_ids'].to(device)\n#         attention_mask = batch['attention_mask'].to(device)\n#         labels = batch['label'].to(device)\n        \n#         # Clear previous gradients\n#         model.zero_grad()\n        \n#         # Forward pass \n#         outputs = model(\n#             input_ids=input_ids,\n#             attention_mask=attention_mask,\n#             labels=labels\n#         )\n        \n#         loss = outputs.loss\n#         logits = outputs.logits\n        \n#         # Backward pass \n#         loss.backward()\n        \n#         # Clip gradients to prevent exploding gradients\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n#         # Update model parameters\n#         optimizer.step()\n        \n#         # Update learning rate\n#         scheduler.step()\n        \n#         total_loss += loss.item()\n        \n#         # Store predictions and labels for metric calculation\n#         logits = logits.detach().cpu().numpy()\n#         label_ids = labels.cpu().numpy()\n        \n#         all_preds.extend(logits)\n#         all_labels.extend(label_ids)\n    \n#     # Calculate metrics\n#     avg_loss = total_loss / len(dataloader)\n#     train_map3 = map_at_3(np.array(all_preds), np.array(all_labels))\n    \n#     return avg_loss, train_map3","metadata":{"_uuid":"66466551-745e-4e1b-bd20-dd9dd078e04e","_cell_guid":"b9834984-aa91-4fda-8d4d-d3cf4fa08624","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.494298Z","iopub.execute_input":"2025-08-29T23:55:38.494888Z","iopub.status.idle":"2025-08-29T23:55:38.505449Z","shell.execute_reply.started":"2025-08-29T23:55:38.494864Z","shell.execute_reply":"2025-08-29T23:55:38.504879Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Define evaluation function\n# def eval_model(model, dataloader, device):\n#     model.eval()  \n#     total_loss = 0\n#     all_preds = []\n#     all_labels = []\n    \n#     # Disable gradient calculation \n#     with torch.no_grad():\n#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n#             input_ids = batch['input_ids'].to(device)\n#             attention_mask = batch['attention_mask'].to(device)\n#             labels = batch['label'].to(device)\n            \n#             # Forward pass\n#             outputs = model(\n#                 input_ids=input_ids,\n#                 attention_mask=attention_mask,\n#                 labels=labels\n#             )\n            \n#             loss = outputs.loss\n#             logits = outputs.logits\n            \n#             total_loss += loss.item()\n            \n#             # Store predictions and labels for metric calculation\n#             logits = logits.detach().cpu().numpy()\n#             label_ids = labels.cpu().numpy()\n            \n#             all_preds.extend(logits)\n#             all_labels.extend(label_ids)\n    \n#     # Calculate metrics\n#     avg_loss = total_loss / len(dataloader)\n#     val_map3 = map_at_3(np.array(all_preds), np.array(all_labels))\n    \n#     return avg_loss, val_map3","metadata":{"_uuid":"8593313b-b82a-49d1-ad53-29055ec073dd","_cell_guid":"2214bbd3-c6ee-4335-8c5a-cd3f07be4ce9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.506331Z","iopub.execute_input":"2025-08-29T23:55:38.506597Z","iopub.status.idle":"2025-08-29T23:55:38.517485Z","shell.execute_reply.started":"2025-08-29T23:55:38.506577Z","shell.execute_reply":"2025-08-29T23:55:38.516888Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Train model\n# from tqdm import tqdm\n# best_val_map3 = 0\n# for epoch in range(EPOCHS):\n#     print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n#     print('-' * 30)\n    \n#     train_loss, train_map3 = train_epoch(\n#         model,\n#         train_dataloader,\n#         optimizer,\n#         scheduler,\n#         device)\n    \n#     print(f\"Train Loss: {train_loss:.4f} | Train MAP@3: {train_map3:.4f}\")\n    \n#     # Evaluate model on validation set\n#     val_loss, val_map3 = eval_model(\n#         model,\n#         val_dataloader,\n#         device)\n    \n#     print(f\"Validation Loss: {val_loss:.4f} | Validation MAP@3: {val_map3:.4f}\")\n    \n#     # Save the best model based on validation MAP@3\n#     if val_map3 > best_val_map3:\n#         best_val_map3 = val_map3\n#         # Save the model and tokenizer\n#         model.save_pretrained(\"./scibert-finetuned\")\n#         tokenizer.save_pretrained(\"./scibert-finetuned\")\n#         print(f\"Saved improved model with Validation MAP@3: {val_map3:.4f}\")\n\n# print(\"\\nFine-tuning completed.\")\n# print(f\"Best Validation MAP@3 achieved: {best_val_map3:.4f}\")","metadata":{"_uuid":"0934457c-5610-4683-9ed6-287c202ef2c7","_cell_guid":"7056a8b6-c4d9-443a-9c21-0e283a91e4ce","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.518276Z","iopub.execute_input":"2025-08-29T23:55:38.518800Z","iopub.status.idle":"2025-08-29T23:55:38.531420Z","shell.execute_reply.started":"2025-08-29T23:55:38.518775Z","shell.execute_reply":"2025-08-29T23:55:38.530805Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Save finetuned RoBERTa transformer model\n# import zipfile\n\n# def zip_model_directory():\n#     zip_name = \"sci_bert_misconception.zip\"\n#     model_dir = \"./sci_bert_misconception\"\n    \n#     # Create zip file\n#     with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#         for root, _, files in os.walk(model_dir):\n#             for file in files:\n#                 file_path = os.path.join(root, file)\n#                 arcname = os.path.relpath(file_path, model_dir)\n#                 zipf.write(file_path, arcname)\n    \n#     print(f\"\\nModel successfully zipped as '{zip_name}'\")\n#     print(f\"Total size: {os.path.getsize(zip_name) / (1024 * 1024):.2f} MB\")\n    \n#     return zip_name\n\n# # Create and display download link \n# try:\n#     from IPython.display import FileLink, display\n#     zip_file = zip_model_directory()\n#     print(\"\\nClick the link below to download the fine-tuned model:\")\n#     display(FileLink(zip_file))\n# except:\n#     zip_file = zip_model_directory()","metadata":{"_uuid":"c65024ac-f081-4245-8f21-b3ac5d9c6c38","_cell_guid":"dd4d6844-bebb-4cc4-8413-e000fff13fe6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T23:55:38.532161Z","iopub.execute_input":"2025-08-29T23:55:38.532394Z","iopub.status.idle":"2025-08-29T23:55:38.547533Z","shell.execute_reply.started":"2025-08-29T23:55:38.532380Z","shell.execute_reply":"2025-08-29T23:55:38.546913Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Make Predictions on Test Set Using Finetuned Model","metadata":{"_uuid":"78f680b1-b96c-4284-8446-e8c52b3878d1","_cell_guid":"9165891a-4776-4a5c-8aa8-b23e0e1bb96d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch.nn.functional as F\nimport joblib\n\n# Set device for computation \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Load the fine-tuned model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/scibert-pre-finetuned/transformers/default/1/scibert-pre-finetuned')\nmodel = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/scibert-pre-finetuned/transformers/default/1/scibert-pre-finetuned')\nmodel.to(device)\nmodel.eval() \nprint(\"Fine-tuned sciBERT model loaded successfully\")\n\n# Load label mapping\nlabel_to_original = joblib.load(\"label_to_original.pkl\")\nnum_classes = len(label_to_original)\nprint(f\"Number of classes: {num_classes}\")\n\n# Pre-process test dataset\ntest_df = pd.read_csv(\"/kaggle/input/map-charting-student-math-misunderstandings/test.csv\")\ntest_df['text_test'] = test_df.apply(create_finetune_text, axis=1)\ntexts = test_df['text_test'].astype(str).tolist()  \n\n# Define dataset class for inference\nclass InferenceDataset(Dataset):    \n    def __init__(self, texts, tokenizer, max_len):\n        # Ensure texts is a list of strings\n        self.texts = [str(t) for t in texts]\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        if idx < 0 or idx >= len(self.texts):\n            raise IndexError(f\"Index {idx} is out of range for dataset with length {len(self.texts)}\")\n        \n        text = self.texts[idx]\n        \n        # Tokenize\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'  # Return PyTorch tensors\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),        \n            'attention_mask': encoding['attention_mask'].flatten(), \n        }\n\n# Parameters\nMAX_LEN = 256\nBATCH_SIZE = 16\n\n# Create dataset and dataloader\ninference_dataset = InferenceDataset(\n    texts=texts,\n    tokenizer=tokenizer,\n    max_len=MAX_LEN\n)\n\ninference_dataloader = DataLoader(\n    inference_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,        \n    pin_memory=True       \n)\n\n# Prediction function\ndef predict_with_scibert(model, dataloader, device):\n    model.eval()\n    all_predictions = []\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to(device)       \n            attention_mask = batch['attention_mask'].to(device) \n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits                         \n            \n            probs = F.softmax(logits, dim=1)              \n            all_predictions.extend(probs.cpu().numpy())    \n    \n    return np.array(all_predictions)\n\n# Run inference\npred_proba = predict_with_scibert(model, inference_dataloader, device)\n\n# Decode predictions: get top-3 class IDs, map to original labels\nsubmission_strings = []\nfor prob in pred_proba:\n    # Get top-3 class indices (descending order)\n    top_3_indices = np.argsort(prob)[-3:][::-1]\n    top_3_labels = [label_to_original[i] for i in top_3_indices]\n    submission_strings.append(\" \".join(top_3_labels))\n\n# Create submission file\nsubmission_df = pd.DataFrame({\n    'row_id': test_df['row_id'],\n    'Category:Misconception': submission_strings\n})\n\n# Save to CSV\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved: submission.csv\")","metadata":{"_uuid":"5fb2bb00-cac9-4513-9f9b-e4a3a0917c48","_cell_guid":"f8e02e6a-b29b-47e6-a375-d76da2fabcd0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T15:16:34.238970Z","iopub.execute_input":"2025-09-03T15:16:34.239328Z","iopub.status.idle":"2025-09-03T15:16:36.439465Z","shell.execute_reply.started":"2025-09-03T15:16:34.239303Z","shell.execute_reply":"2025-09-03T15:16:36.438073Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Using device: cpu\nFine-tuned sciBERT model loaded successfully\nNumber of classes: 60\nSubmission file saved: submission.csv\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"submission_df.head()","metadata":{"_uuid":"44caae20-aa31-41fc-9d2e-1cc664448fc2","_cell_guid":"cf712a83-310a-407b-b0f0-a18a0246c36a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-03T15:16:38.621794Z","iopub.execute_input":"2025-09-03T15:16:38.622618Z","iopub.status.idle":"2025-09-03T15:16:38.632713Z","shell.execute_reply.started":"2025-09-03T15:16:38.622579Z","shell.execute_reply":"2025-09-03T15:16:38.631422Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   row_id                             Category:Misconception\n0   36696  True_Correct:NA True_Neither:NA True_Misconcep...\n1   36697  False_Misconception:WNB False_Neither:NA False...\n2   36698  True_Neither:NA True_Correct:NA True_Misconcep...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>Category:Misconception</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>True_Correct:NA True_Neither:NA True_Misconcep...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>False_Misconception:WNB False_Neither:NA False...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36698</td>\n      <td>True_Neither:NA True_Correct:NA True_Misconcep...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29}]}