{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a69ee17",
   "metadata": {
    "_cell_guid": "5fd3d91a-567f-4ef7-9b9d-cb524befdf55",
    "_uuid": "2a9297b6-f347-4772-847a-4f5158588d75",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006997,
     "end_time": "2025-09-04T08:48:19.242669",
     "exception": false,
     "start_time": "2025-09-04T08:48:19.235672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAP - Charting Student Math Misunderstandings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874ca0b",
   "metadata": {
    "papermill": {
     "duration": 0.005599,
     "end_time": "2025-09-04T08:48:19.254887",
     "exception": false,
     "start_time": "2025-09-04T08:48:19.249288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb518a",
   "metadata": {
    "_cell_guid": "aeff8aaf-3cce-49e4-b9c2-0b179be393ea",
    "_uuid": "d739f6b5-50d2-4dc5-8624-d7f4ee855ba6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005336,
     "end_time": "2025-09-04T08:48:19.266114",
     "exception": false,
     "start_time": "2025-09-04T08:48:19.260778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53629986",
   "metadata": {
    "_cell_guid": "9a913737-80d3-40e9-b3f3-3e78c01e6ac0",
    "_uuid": "8efff134-af25-4b87-8434-874e129a866c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:19.279273Z",
     "iopub.status.busy": "2025-09-04T08:48:19.278881Z",
     "iopub.status.idle": "2025-09-04T08:48:57.118636Z",
     "shell.execute_reply": "2025-09-04T08:48:57.117836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 37.84858,
     "end_time": "2025-09-04T08:48:57.120365",
     "exception": false,
     "start_time": "2025-09-04T08:48:19.271785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 08:48:24.991097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756975705.226918      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756975705.296545      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, auc, roc_curve, roc_auc_score, precision_recall_fscore_support\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Import tensorflow, and keras modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM, Input, Masking, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Import transformers and pytorch modules\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, TrainingArguments, Trainer,  DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorForLanguageModeling\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaForSequenceClassification,DataCollatorForLanguageModeling\n",
    "from transformers import DistilBertForSequenceClassification, DataCollatorForLanguageModeling\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset, Dataset as HFDataset, DatasetDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaForSequenceClassification,DataCollatorForLanguageModeling\n",
    "from transformers import DistilBertForSequenceClassification, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b20f3f",
   "metadata": {
    "_cell_guid": "39ca4580-c661-4e86-a75b-19616d9997e0",
    "_uuid": "efc9e40b-80a6-4186-99b0-bdeb54211143",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.134066Z",
     "iopub.status.busy": "2025-09-04T08:48:57.133414Z",
     "iopub.status.idle": "2025-09-04T08:48:57.380154Z",
     "shell.execute_reply": "2025-09-04T08:48:57.379130Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.255386,
     "end_time": "2025-09-04T08:48:57.381951",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.126565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Load & train and test data\n",
    "data = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7988e75a",
   "metadata": {
    "_cell_guid": "125e357d-263e-4b2f-bcee-018134132dad",
    "_uuid": "0f2aa5c3-d21f-49fb-a951-de4713481c55",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.396248Z",
     "iopub.status.busy": "2025-09-04T08:48:57.395679Z",
     "iopub.status.idle": "2025-09-04T08:48:57.440489Z",
     "shell.execute_reply": "2025-09-04T08:48:57.439747Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.054201,
     "end_time": "2025-09-04T08:48:57.442227",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.388026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0440f7",
   "metadata": {
    "_cell_guid": "21871582-6c90-4b59-a702-4980f91f3d75",
    "_uuid": "d991ee2e-3d4f-4dcd-b2d0-e2c66bad08d1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.456410Z",
     "iopub.status.busy": "2025-09-04T08:48:57.456052Z",
     "iopub.status.idle": "2025-09-04T08:48:57.463855Z",
     "shell.execute_reply": "2025-09-04T08:48:57.462952Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016591,
     "end_time": "2025-09-04T08:48:57.465254",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.448663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Impute missing values for the `Misconception` column with NA\n",
    "data['Misconception'] = data['Misconception'].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab3c8a6",
   "metadata": {
    "_cell_guid": "017fb7d3-8ec3-40ea-87bb-c5e054d83ebd",
    "_uuid": "190544b6-b69e-444f-bfa5-6e70dd2692d3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.478462Z",
     "iopub.status.busy": "2025-09-04T08:48:57.478125Z",
     "iopub.status.idle": "2025-09-04T08:48:57.502805Z",
     "shell.execute_reply": "2025-09-04T08:48:57.502003Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.032901,
     "end_time": "2025-09-04T08:48:57.504132",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.471231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of classes: 65\n",
      " Label range: 0 to 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_to_original.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['combined_label'] = data['Category'].astype(str) + ':' + data['Misconception'].astype(str)\n",
    "cat = pd.Categorical(data['combined_label'])\n",
    "y = cat.codes\n",
    "num_classes = len(cat.categories)\n",
    "label_to_original = dict(enumerate(cat.categories))\n",
    "\n",
    "print(f\" Number of classes: {num_classes}\")\n",
    "print(f\" Label range: 0 to {num_classes - 1}\")\n",
    "\n",
    "# Save mapping\n",
    "joblib.dump(label_to_original, \"label_to_original.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617854bc",
   "metadata": {
    "_cell_guid": "bee0891d-e7ba-4907-b7ab-f484fc7ecd3d",
    "_uuid": "afd14737-7389-438d-b8ec-5e9f931761d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.518316Z",
     "iopub.status.busy": "2025-09-04T08:48:57.518044Z",
     "iopub.status.idle": "2025-09-04T08:48:57.557412Z",
     "shell.execute_reply": "2025-09-04T08:48:57.556563Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.048186,
     "end_time": "2025-09-04T08:48:57.558842",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.510656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>MC_Answer</th>\n",
       "      <th>StudentExplanation</th>\n",
       "      <th>Category</th>\n",
       "      <th>Misconception</th>\n",
       "      <th>combined_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>0ne third is equal to tree nineth</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  QuestionId                                       QuestionText  \\\n",
       "0       0       31772  What fraction of the shape is not shaded? Give...   \n",
       "1       1       31772  What fraction of the shape is not shaded? Give...   \n",
       "\n",
       "           MC_Answer                                 StudentExplanation  \\\n",
       "0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n",
       "1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n",
       "\n",
       "       Category Misconception   combined_label  \n",
       "0  True_Correct            NA  True_Correct:NA  \n",
       "1  True_Correct            NA  True_Correct:NA  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop labels that have less than 1 entities for the `combined_label` column\n",
    "classes_to_keep = data['combined_label'].value_counts()[data['combined_label'].value_counts() >= 2].index\n",
    "train = data[data['combined_label'].isin(classes_to_keep)] \n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b856056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.572515Z",
     "iopub.status.busy": "2025-09-04T08:48:57.572202Z",
     "iopub.status.idle": "2025-09-04T08:48:57.599177Z",
     "shell.execute_reply": "2025-09-04T08:48:57.598261Z"
    },
    "papermill": {
     "duration": 0.035394,
     "end_time": "2025-09-04T08:48:57.600613",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.565219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36691 entries, 0 to 36695\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   row_id              36691 non-null  int64 \n",
      " 1   QuestionId          36691 non-null  int64 \n",
      " 2   QuestionText        36691 non-null  object\n",
      " 3   MC_Answer           36691 non-null  object\n",
      " 4   StudentExplanation  36691 non-null  object\n",
      " 5   Category            36691 non-null  object\n",
      " 6   Misconception       36691 non-null  object\n",
      " 7   combined_label      36691 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3afe86a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.614476Z",
     "iopub.status.busy": "2025-09-04T08:48:57.613813Z",
     "iopub.status.idle": "2025-09-04T08:48:57.628447Z",
     "shell.execute_reply": "2025-09-04T08:48:57.627701Z"
    },
    "papermill": {
     "duration": 0.023021,
     "end_time": "2025-09-04T08:48:57.629955",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.606934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misconception classes: 60\n",
      "Label range: 0 to 59\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels to numeric values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(train['combined_label'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Save label mapping for later use during inference\n",
    "label_to_original = dict(enumerate(le.classes_))\n",
    "joblib.dump(label_to_original, \"label_to_original.pkl\")\n",
    "print(f\"Number of misconception classes: {num_classes}\")\n",
    "print(f\"Label range: 0 to {num_classes-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a0cee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.644296Z",
     "iopub.status.busy": "2025-09-04T08:48:57.643535Z",
     "iopub.status.idle": "2025-09-04T08:48:57.647516Z",
     "shell.execute_reply": "2025-09-04T08:48:57.646775Z"
    },
    "papermill": {
     "duration": 0.012283,
     "end_time": "2025-09-04T08:48:57.648800",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.636517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine if CUDA (GPU) is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb2cc97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.662632Z",
     "iopub.status.busy": "2025-09-04T08:48:57.661911Z",
     "iopub.status.idle": "2025-09-04T08:48:57.674287Z",
     "shell.execute_reply": "2025-09-04T08:48:57.673423Z"
    },
    "papermill": {
     "duration": 0.020726,
     "end_time": "2025-09-04T08:48:57.675789",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.655063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18774139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.689484Z",
     "iopub.status.busy": "2025-09-04T08:48:57.689196Z",
     "iopub.status.idle": "2025-09-04T08:48:57.693853Z",
     "shell.execute_reply": "2025-09-04T08:48:57.693157Z"
    },
    "papermill": {
     "duration": 0.012892,
     "end_time": "2025-09-04T08:48:57.695083",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.682191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Pretrain the scibert transformer\n",
    "\n",
    "# # Create pretraining corpus \n",
    "# def create_pretrain_text(row):\n",
    "#     return (\n",
    "#         # f\"[CLS] [question id] {row['QuestionId']} \"\n",
    "#         f\"[CLC] [question] {row['QuestionText']}\"\n",
    "#         f\"[answer] {row['MC_Answer']} [SEP]\"\n",
    "#         f\"[explanation] {row['StudentExplanation']} [SEP]\"\n",
    "#         f\"[category] {row['Category']} [SEP]\"\n",
    "#         f\"[misconception] {row['Misconception']} [SEP]\"\n",
    "#     )\n",
    "\n",
    "# pretrain_corpus = train_data.apply(create_pretrain_text, axis=1).tolist()\n",
    "\n",
    "# # Create a Hugging Face Dataset\n",
    "# dataset = Dataset.from_dict({'text': pretrain_corpus}) \n",
    "\n",
    "# # Load tokenizer and model\n",
    "# scibert_base = '/kaggle/input/scibert-base-offline/transformers/default/1/scibert-base-offline'\n",
    "# # scibert_base = \"allenai/scibert_scivocab_uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(scibert_base)\n",
    "# model = AutoModelForMaskedLM.from_pretrained(scibert_base).to(device)\n",
    "\n",
    "# # Tokenize the dataset with dynamic padding\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "# tokenized_dataset.set_format('torch')  \n",
    "\n",
    "# # Data collator for MLM \n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=True,\n",
    "#     mlm_probability=0.20 \n",
    "# )\n",
    "\n",
    "# # Training arguments with optimizations\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./scibert-pretrain',\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     save_steps=5_000,\n",
    "#     save_total_limit=2,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=500,  \n",
    "#     report_to=[],\n",
    "#     learning_rate=2e-5,\n",
    "#     warmup_steps=500,\n",
    "#     fp16=True,\n",
    "# )\n",
    "\n",
    "# # Trainer with optimized settings\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     data_collator=data_collator,\n",
    "# )\n",
    "\n",
    "# # Start pretraining\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the pretrained model\n",
    "# model.save_pretrained('./scibert-pretrained')\n",
    "# tokenizer.save_pretrained('./scibert-pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be02183c",
   "metadata": {
    "_cell_guid": "b0889a34-277b-4435-a96e-b50e756c1e4e",
    "_uuid": "8fed60f0-6090-4b7d-8442-3dbd0504a024",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.708756Z",
     "iopub.status.busy": "2025-09-04T08:48:57.708365Z",
     "iopub.status.idle": "2025-09-04T08:48:57.712731Z",
     "shell.execute_reply": "2025-09-04T08:48:57.711809Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01277,
     "end_time": "2025-09-04T08:48:57.714096",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.701326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create finetuning corpus \n",
    "def create_finetune_text(row):\n",
    "    return (\n",
    "        # f\"[CLS] [question id] {row['QuestionId']}\"\n",
    "        f\"[CLS] [question] {row['QuestionText']}\"\n",
    "        f\"[answer] {row['MC_Answer']} [SEP]\"\n",
    "        f\"[explanation] {row['StudentExplanation']} [SEP]\"\n",
    "    )\n",
    "\n",
    "# train_data['train_text'] = train_data.apply(create_finetune_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3155d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.727847Z",
     "iopub.status.busy": "2025-09-04T08:48:57.727519Z",
     "iopub.status.idle": "2025-09-04T08:48:57.731386Z",
     "shell.execute_reply": "2025-09-04T08:48:57.730582Z"
    },
    "papermill": {
     "duration": 0.012336,
     "end_time": "2025-09-04T08:48:57.732785",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.720449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf2f0b23",
   "metadata": {
    "_cell_guid": "17f736f6-a79f-4344-9098-ac1be91ff593",
    "_uuid": "852960de-3ca6-4987-8ea2-c47721236d2a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.747231Z",
     "iopub.status.busy": "2025-09-04T08:48:57.746651Z",
     "iopub.status.idle": "2025-09-04T08:48:57.750306Z",
     "shell.execute_reply": "2025-09-04T08:48:57.749524Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012493,
     "end_time": "2025-09-04T08:48:57.751851",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.739358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "# train_texts, val_texts, train_labels, val_labels = train_test_split(train_data['text'].values, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be833c",
   "metadata": {
    "papermill": {
     "duration": 0.006,
     "end_time": "2025-09-04T08:48:57.764437",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.758437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune the SciBERT Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff2c686",
   "metadata": {
    "_cell_guid": "e67237d9-9e9d-4fdb-9485-be511be26a11",
    "_uuid": "87bdcf9a-0a78-4e17-9f5c-93bd4895d3fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.778326Z",
     "iopub.status.busy": "2025-09-04T08:48:57.778038Z",
     "iopub.status.idle": "2025-09-04T08:48:57.781805Z",
     "shell.execute_reply": "2025-09-04T08:48:57.780977Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012203,
     "end_time": "2025-09-04T08:48:57.783132",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.770929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device: {device}\")\n",
    "# if device.type == 'cuda':\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a136e57",
   "metadata": {
    "_cell_guid": "b4ffc16f-2741-4337-b8d8-bf674d25ded4",
    "_uuid": "4c295ba9-cb8c-4c43-b091-ef93c2b4a99f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.797843Z",
     "iopub.status.busy": "2025-09-04T08:48:57.797169Z",
     "iopub.status.idle": "2025-09-04T08:48:57.800817Z",
     "shell.execute_reply": "2025-09-04T08:48:57.800060Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012449,
     "end_time": "2025-09-04T08:48:57.802117",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.789668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load RoBERTa tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./scibert-pretrained\")\n",
    "# MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "356bca8f",
   "metadata": {
    "_cell_guid": "e7aec855-d936-40eb-9746-6e2c492c19b1",
    "_uuid": "07454838-24cd-46ab-8bb8-bee111c135de",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.816070Z",
     "iopub.status.busy": "2025-09-04T08:48:57.815770Z",
     "iopub.status.idle": "2025-09-04T08:48:57.820006Z",
     "shell.execute_reply": "2025-09-04T08:48:57.819321Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012756,
     "end_time": "2025-09-04T08:48:57.821414",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.808658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define custom dataset class\n",
    "# class MathMisconceptionDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_len):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx])\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         # Tokenize the text \n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             add_special_tokens=True,      \n",
    "#             max_length=self.max_len,      \n",
    "#             return_token_type_ids=False,  \n",
    "#             padding='max_length',         \n",
    "#             truncation=True,              \n",
    "#             return_attention_mask=True,   \n",
    "#             return_tensors='pt',         \n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'label': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# # Create dataset instances for training and validation\n",
    "# train_dataset = MathMisconceptionDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "# val_dataset = MathMisconceptionDataset(val_texts, val_labels, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4a35bf",
   "metadata": {
    "_cell_guid": "0d81b9f2-db6b-4a37-9904-bf45b97466ee",
    "_uuid": "e447cc0f-3f80-4e8c-bc95-6beaf0876cbe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.835972Z",
     "iopub.status.busy": "2025-09-04T08:48:57.835693Z",
     "iopub.status.idle": "2025-09-04T08:48:57.839446Z",
     "shell.execute_reply": "2025-09-04T08:48:57.838694Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012397,
     "end_time": "2025-09-04T08:48:57.840884",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.828487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Data Loading\n",
    "\n",
    "# BATCH_SIZE = 16 \n",
    "\n",
    "# # Create data loaders (train set)\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,      \n",
    "#     num_workers=2,     \n",
    "#     pin_memory=True)\n",
    "\n",
    "# # Create data loaders (validation set)\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False,     \n",
    "#     num_workers=2,\n",
    "#     pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae1fbcbf",
   "metadata": {
    "_cell_guid": "09f6c3e7-f4fc-4f0e-86fc-b4869d535007",
    "_uuid": "f87a317a-0d7f-48cb-bd4c-0fcb249caed4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.855117Z",
     "iopub.status.busy": "2025-09-04T08:48:57.854556Z",
     "iopub.status.idle": "2025-09-04T08:48:57.858684Z",
     "shell.execute_reply": "2025-09-04T08:48:57.857830Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01264,
     "end_time": "2025-09-04T08:48:57.859975",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.847335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Configure model\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"./scibert-pretrained\",\n",
    "#     num_labels=num_classes,  \n",
    "#     output_attentions=False, \n",
    "#     output_hidden_states=False)\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Configure optimizer\n",
    "# optimizer = optim.AdamW(\n",
    "#     model.parameters(),\n",
    "#     lr=2e-5,          \n",
    "#     eps=1e-8,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "# # Define training parameters\n",
    "# EPOCHS = 4            \n",
    "# WARMUP_STEPS = 0      \n",
    "\n",
    "# # Calculate total training steps \n",
    "# total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# # Create learning rate scheduler\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=WARMUP_STEPS,\n",
    "#     num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf8afe5",
   "metadata": {
    "_cell_guid": "f2c8e618-6f04-4c87-abd6-630bf2e14471",
    "_uuid": "e738be4d-2343-402d-879e-73878c6fd80d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.874180Z",
     "iopub.status.busy": "2025-09-04T08:48:57.873642Z",
     "iopub.status.idle": "2025-09-04T08:48:57.877628Z",
     "shell.execute_reply": "2025-09-04T08:48:57.876881Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012566,
     "end_time": "2025-09-04T08:48:57.878956",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.866390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define map3 metric\n",
    "# def map_at_3(predictions, true_labels):\n",
    "    \n",
    "#     # Get top-3 predicted class indices for each sample in descending order\n",
    "#     top_3_pred = np.argsort(predictions, axis=1)[:, -3:][:, ::-1]\n",
    "\n",
    "#     # List average precisions \n",
    "#     aps = []  \n",
    "#     for i in range(len(true_labels)):\n",
    "#         true_label = true_labels[i]\n",
    "#         preds = top_3_pred[i]\n",
    "#         hits = (preds == true_label)\n",
    "#         if not np.any(hits):\n",
    "#             aps.append(0.0)  \n",
    "#         else:\n",
    "#             rank = np.where(hits)[0][0] + 1\n",
    "#             precision_at_k = 1.0 / rank\n",
    "#             aps.append(precision_at_k)\n",
    "            \n",
    "#     return np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8284dbf2",
   "metadata": {
    "_cell_guid": "b9834984-aa91-4fda-8d4d-d3cf4fa08624",
    "_uuid": "66466551-745e-4e1b-bd20-dd9dd078e04e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.893371Z",
     "iopub.status.busy": "2025-09-04T08:48:57.892601Z",
     "iopub.status.idle": "2025-09-04T08:48:57.897177Z",
     "shell.execute_reply": "2025-09-04T08:48:57.896372Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013197,
     "end_time": "2025-09-04T08:48:57.898635",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.885438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define training function\n",
    "# def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     # Process batches with progress bar\n",
    "#     for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "        \n",
    "#         # Clear previous gradients\n",
    "#         model.zero_grad()\n",
    "        \n",
    "#         # Forward pass \n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "        \n",
    "#         loss = outputs.loss\n",
    "#         logits = outputs.logits\n",
    "        \n",
    "#         # Backward pass \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Clip gradients to prevent exploding gradients\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "#         # Update model parameters\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Update learning rate\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         # Store predictions and labels for metric calculation\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = labels.cpu().numpy()\n",
    "        \n",
    "#         all_preds.extend(logits)\n",
    "#         all_labels.extend(label_ids)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     train_map3 = map_at_3(np.array(all_preds), np.array(all_labels))\n",
    "    \n",
    "#     return avg_loss, train_map3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20de09e7",
   "metadata": {
    "_cell_guid": "2214bbd3-c6ee-4335-8c5a-cd3f07be4ce9",
    "_uuid": "8593313b-b82a-49d1-ad53-29055ec073dd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.912942Z",
     "iopub.status.busy": "2025-09-04T08:48:57.912222Z",
     "iopub.status.idle": "2025-09-04T08:48:57.916535Z",
     "shell.execute_reply": "2025-09-04T08:48:57.915779Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012765,
     "end_time": "2025-09-04T08:48:57.917891",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.905126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define evaluation function\n",
    "# def eval_model(model, dataloader, device):\n",
    "#     model.eval()  \n",
    "#     total_loss = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     # Disable gradient calculation \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['label'].to(device)\n",
    "            \n",
    "#             # Forward pass\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask,\n",
    "#                 labels=labels\n",
    "#             )\n",
    "            \n",
    "#             loss = outputs.loss\n",
    "#             logits = outputs.logits\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#             # Store predictions and labels for metric calculation\n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "#             label_ids = labels.cpu().numpy()\n",
    "            \n",
    "#             all_preds.extend(logits)\n",
    "#             all_labels.extend(label_ids)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     val_map3 = map_at_3(np.array(all_preds), np.array(all_labels))\n",
    "    \n",
    "#     return avg_loss, val_map3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "561d41bf",
   "metadata": {
    "_cell_guid": "7056a8b6-c4d9-443a-9c21-0e283a91e4ce",
    "_uuid": "0934457c-5610-4683-9ed6-287c202ef2c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.932160Z",
     "iopub.status.busy": "2025-09-04T08:48:57.931365Z",
     "iopub.status.idle": "2025-09-04T08:48:57.935612Z",
     "shell.execute_reply": "2025-09-04T08:48:57.934841Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012726,
     "end_time": "2025-09-04T08:48:57.936939",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.924213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train model\n",
    "# from tqdm import tqdm\n",
    "# best_val_map3 = 0\n",
    "# for epoch in range(EPOCHS):\n",
    "#     print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "#     print('-' * 30)\n",
    "    \n",
    "#     train_loss, train_map3 = train_epoch(\n",
    "#         model,\n",
    "#         train_dataloader,\n",
    "#         optimizer,\n",
    "#         scheduler,\n",
    "#         device)\n",
    "    \n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train MAP@3: {train_map3:.4f}\")\n",
    "    \n",
    "#     # Evaluate model on validation set\n",
    "#     val_loss, val_map3 = eval_model(\n",
    "#         model,\n",
    "#         val_dataloader,\n",
    "#         device)\n",
    "    \n",
    "#     print(f\"Validation Loss: {val_loss:.4f} | Validation MAP@3: {val_map3:.4f}\")\n",
    "    \n",
    "#     # Save the best model based on validation MAP@3\n",
    "#     if val_map3 > best_val_map3:\n",
    "#         best_val_map3 = val_map3\n",
    "#         # Save the model and tokenizer\n",
    "#         model.save_pretrained(\"./scibert-finetuned\")\n",
    "#         tokenizer.save_pretrained(\"./scibert-finetuned\")\n",
    "#         print(f\"Saved improved model with Validation MAP@3: {val_map3:.4f}\")\n",
    "\n",
    "# print(\"\\nFine-tuning completed.\")\n",
    "# print(f\"Best Validation MAP@3 achieved: {best_val_map3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c30011d5",
   "metadata": {
    "_cell_guid": "dd4d6844-bebb-4cc4-8413-e000fff13fe6",
    "_uuid": "c65024ac-f081-4245-8f21-b3ac5d9c6c38",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.951335Z",
     "iopub.status.busy": "2025-09-04T08:48:57.950620Z",
     "iopub.status.idle": "2025-09-04T08:48:57.954729Z",
     "shell.execute_reply": "2025-09-04T08:48:57.953994Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012364,
     "end_time": "2025-09-04T08:48:57.955955",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.943591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save finetuned RoBERTa transformer model\n",
    "# import zipfile\n",
    "\n",
    "# def zip_model_directory():\n",
    "#     zip_name = \"sci_bert_misconception.zip\"\n",
    "#     model_dir = \"./sci_bert_misconception\"\n",
    "    \n",
    "#     # Create zip file\n",
    "#     with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#         for root, _, files in os.walk(model_dir):\n",
    "#             for file in files:\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 arcname = os.path.relpath(file_path, model_dir)\n",
    "#                 zipf.write(file_path, arcname)\n",
    "    \n",
    "#     print(f\"\\nModel successfully zipped as '{zip_name}'\")\n",
    "#     print(f\"Total size: {os.path.getsize(zip_name) / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "#     return zip_name\n",
    "\n",
    "# # Create and display download link \n",
    "# try:\n",
    "#     from IPython.display import FileLink, display\n",
    "#     zip_file = zip_model_directory()\n",
    "#     print(\"\\nClick the link below to download the fine-tuned model:\")\n",
    "#     display(FileLink(zip_file))\n",
    "# except:\n",
    "#     zip_file = zip_model_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827ec0f",
   "metadata": {
    "_cell_guid": "9165891a-4776-4a5c-8aa8-b23e0e1bb96d",
    "_uuid": "78f680b1-b96c-4284-8446-e8c52b3878d1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0061,
     "end_time": "2025-09-04T08:48:57.968516",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.962416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Predictions on Test Set Using Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7155c0c5",
   "metadata": {
    "_cell_guid": "f8e02e6a-b29b-47e6-a375-d76da2fabcd0",
    "_uuid": "5fb2bb00-cac9-4513-9f9b-e4a3a0917c48",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:48:57.983185Z",
     "iopub.status.busy": "2025-09-04T08:48:57.982894Z",
     "iopub.status.idle": "2025-09-04T08:49:04.791643Z",
     "shell.execute_reply": "2025-09-04T08:49:04.790712Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.817911,
     "end_time": "2025-09-04T08:49:04.793008",
     "exception": false,
     "start_time": "2025-09-04T08:48:57.975097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Fine-tuned sciBERT model loaded successfully\n",
      "Number of classes: 60\n",
      "Submission file saved: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "\n",
    "# Set device for computation \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/scibert-pre-finetuned-0.9350/transformers/default/1/scibert-pre-finetuned 0.9350')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/kaggle/input/scibert-pre-finetuned-0.9350/transformers/default/1/scibert-pre-finetuned 0.9350')\n",
    "model.to(device)\n",
    "model.eval() \n",
    "print(\"Fine-tuned sciBERT model loaded successfully\")\n",
    "\n",
    "# Load label mapping\n",
    "label_to_original = joblib.load(\"label_to_original.pkl\")\n",
    "num_classes = len(label_to_original)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Pre-process test dataset\n",
    "test_df = pd.read_csv(\"/kaggle/input/map-charting-student-math-misunderstandings/test.csv\")\n",
    "test_df['text_test'] = test_df.apply(create_finetune_text, axis=1)\n",
    "texts = test_df['text_test'].astype(str).tolist()  \n",
    "\n",
    "# Define dataset class for inference\n",
    "class InferenceDataset(Dataset):    \n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        # Ensure texts is a list of strings\n",
    "        self.texts = [str(t) for t in texts]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self.texts):\n",
    "            raise IndexError(f\"Index {idx} is out of range for dataset with length {len(self.texts)}\")\n",
    "        \n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),        \n",
    "            'attention_mask': encoding['attention_mask'].flatten(), \n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create dataset and dataloader\n",
    "inference_dataset = InferenceDataset(\n",
    "    texts=texts,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "inference_dataloader = DataLoader(\n",
    "    inference_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,        \n",
    "    pin_memory=True       \n",
    ")\n",
    "\n",
    "# Prediction function\n",
    "def predict_with_scibert(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)       \n",
    "            attention_mask = batch['attention_mask'].to(device) \n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits                         \n",
    "            \n",
    "            probs = F.softmax(logits, dim=1)              \n",
    "            all_predictions.extend(probs.cpu().numpy())    \n",
    "    \n",
    "    return np.array(all_predictions)\n",
    "\n",
    "# Run inference\n",
    "pred_proba = predict_with_scibert(model, inference_dataloader, device)\n",
    "\n",
    "# Decode predictions: get top-3 class IDs, map to original labels\n",
    "submission_strings = []\n",
    "for prob in pred_proba:\n",
    "    # Get top-3 class indices (descending order)\n",
    "    top_3_indices = np.argsort(prob)[-3:][::-1]\n",
    "    top_3_labels = [label_to_original[i] for i in top_3_indices]\n",
    "    submission_strings.append(\" \".join(top_3_labels))\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'row_id': test_df['row_id'],\n",
    "    'Category:Misconception': submission_strings\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c30a4b0f",
   "metadata": {
    "_cell_guid": "cf712a83-310a-407b-b0f0-a18a0246c36a",
    "_uuid": "44caae20-aa31-41fc-9d2e-1cc664448fc2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-04T08:49:04.806984Z",
     "iopub.status.busy": "2025-09-04T08:49:04.806698Z",
     "iopub.status.idle": "2025-09-04T08:49:04.814352Z",
     "shell.execute_reply": "2025-09-04T08:49:04.813561Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015999,
     "end_time": "2025-09-04T08:49:04.815553",
     "exception": false,
     "start_time": "2025-09-04T08:49:04.799554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Category:Misconception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36696</td>\n",
       "      <td>True_Correct:NA True_Neither:NA False_Correct:NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36697</td>\n",
       "      <td>False_Misconception:WNB False_Neither:NA False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36698</td>\n",
       "      <td>True_Neither:NA True_Correct:NA True_Misconcep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                             Category:Misconception\n",
       "0   36696   True_Correct:NA True_Neither:NA False_Correct:NA\n",
       "1   36697  False_Misconception:WNB False_Neither:NA False...\n",
       "2   36698  True_Neither:NA True_Correct:NA True_Misconcep..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "modelId": 432264,
     "modelInstanceId": 414496,
     "sourceId": 529891,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 435712,
     "modelInstanceId": 418051,
     "sourceId": 541597,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 435769,
     "modelInstanceId": 418104,
     "sourceId": 541860,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 435846,
     "modelInstanceId": 418182,
     "sourceId": 542711,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 437030,
     "modelInstanceId": 419371,
     "sourceId": 548733,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 437159,
     "modelInstanceId": 419512,
     "sourceId": 548996,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 441496,
     "modelInstanceId": 423985,
     "sourceId": 557916,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 441841,
     "modelInstanceId": 424349,
     "sourceId": 559586,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.451918,
   "end_time": "2025-09-04T08:49:07.774786",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T08:48:14.322868",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
